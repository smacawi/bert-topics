{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from models.bert_topic_model import BertTopicModel\n",
    "from utils import get_stopwords\n",
    "\n",
    "import pickle\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_model_data = pickle.load(open(\"bert_embedders/attentions_finetuned_sent_embeddings.pkl\", \"rb\"))\n",
    "texts, _, attentions, embeddings = zip(*all_model_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "bertTM = BertTopicModel(texts = texts, \n",
    "                        attentions = attentions, \n",
    "                        embeddings = embeddings,\n",
    "                        n_clusters = 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting kmeans model.\n",
      "The number of texts per label are:\n",
      "{0: 2632, 1: 4438, 2: 1034, 3: 826, 4: 670, 5: 798, 6: 2858, 7: 4467, 8: 4074}\n"
     ]
    }
   ],
   "source": [
    "bertTM.get_clusters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1346\n"
     ]
    }
   ],
   "source": [
    "hashtags = ['nlwhiteout', 'nlweather', 'newfoundland', 'nlblizzard2020', 'nlstm2020',\n",
    "            'snowmaggedon2020', 'stmageddon2020','stormageddon2020', 'newfoundland2020','snowpocalypse2020',\n",
    "            'snowmageddon','nlstm', 'nlwx', 'nlwx2020','nlblizzard', 'nlstorm2020', \n",
    "            'unk', 'https','http',\n",
    "            '#', '@', '…', \"'\", \"’\", \"[unk]\", \"\\\"\", \";\", \"*\", \"_\", \"amp\", \"&\", \"“\", \"”\", \"rt\"]\n",
    "stopwords = get_stopwords(hashtags = hashtags)\n",
    "print(len(stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering attentions.\n",
      "7074\n"
     ]
    }
   ],
   "source": [
    "bertTM.get_features(stopwords, phrasing = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Determining cluster components. This will take a while. \n",
      "    Progress will be printed for every 500th processed property.\n",
      "        \n",
      "Processed 5000 texts in 3.15 seconds.\n",
      "Processed 10000 texts in 6.33 seconds.\n",
      "Processed 15000 texts in 10.89 seconds.\n",
      "Processed 20000 texts in 14.33 seconds.\n",
      "Processed 25000 texts in 17.46 seconds.\n",
      "Processed 30000 texts in 20.67 seconds.\n",
      "Processed 35000 texts in 23.83 seconds.\n",
      "Processed 40000 texts in 27.32 seconds.\n",
      "Processed 45000 texts in 30.49 seconds.\n",
      "Processed 50000 texts in 33.74 seconds.\n",
      "Processed 55000 texts in 36.92 seconds.\n",
      "Processed 60000 texts in 40.27 seconds.\n",
      "Processed 65000 texts in 43.57 seconds.\n",
      "Processed 70000 texts in 46.73 seconds.\n",
      "Processed 75000 texts in 49.92 seconds.\n",
      "Processed 80000 texts in 53.27 seconds.\n",
      "Processed 85000 texts in 56.7 seconds.\n",
      "Processed 90000 texts in 59.78 seconds.\n",
      "Processed 95000 texts in 62.97 seconds.\n",
      "Processed 100000 texts in 66.1 seconds.\n",
      "Processed 105000 texts in 69.55 seconds.\n",
      "Processed 110000 texts in 74.07 seconds.\n",
      "Processed 115000 texts in 77.3 seconds.\n",
      "Processed 120000 texts in 80.48 seconds.\n",
      "Processed 125000 texts in 83.87 seconds.\n",
      "Processed 130000 texts in 87.21 seconds.\n",
      "Finished determining a total of 130110 cluster components. Total time 87.28 seconds.\n"
     ]
    }
   ],
   "source": [
    "ngram = (1, 3)\n",
    "bertTM.determine_cluster_components(ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bertTM.get_tfidf_components()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Allen NLP",
   "language": "python",
   "name": "allennlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
